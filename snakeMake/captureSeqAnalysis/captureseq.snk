import os
import subprocess as sp
from glob import glob
import re

shell.executable("/usr/bin/bash")

r1_regex = '_R1_'
r2_regex = '_R2_'
fq_R1_names = {}
fq_R2_names = {}
fq_names = glob('fastq-*/*.fastq.gz', recursive=True)
for s in config['samples'].keys():
    f = glob(f'{config["samples"][s]}*.fastq.gz')
    if r1_regex in f:
        fq_R1_names[s] = f
    elif r2_regex in f:
        fq_R2_names[s] = f

configfile : "config.yaml"
WKDIR = os.getcwd()

os.makedirs("logs", exist_ok=True)
os.makedirs("TEMP", exist_ok=True)
os.makedirs("final", exist_ok=True)

def getAssemblyName(v):
    return os.path.basename(v).replace('.fa', '')

SAMPLES = config["samples"]

wildcard_constraints:
    sample = "|".join(SAMPLES)

localrules: modify_and_index, tabulate_spades

onerror:
    print("Error! Mailing log...")
    shell("tail -n 100 {log} | mail -s 'CaptureSeq' derek.bickhart@hendrix-genetics.com")
    print("Done")

rule all:
    input:
        expand("linkage/{sample}/{sample}.clusters.tab", sample=SAMPLES)

rule align_vector:
    input:
        fq1 = lambda wildcards: fq_R1_names[wildcards.sample],
        fq2 = lambda wildcards: fq_R2_names[wildcards.sample],
        ref = config["vector"]
    output:
        bam = "mapped/{sample}.vectormap.bam",
        bai = "mapped/{sample}.vectormap.bam.bai"
    threads: 10
    params:
        sname = "{sample}"
    log:
        "logs/{sample}/vectormap.log"
    resources:
        mem_mb=25000,
        runtime="1d",
        threads=10,
        outstr=lambda wildcards: f'logs/vectormap/{wildcards.sample}'
    shell:
        """
        minimap2 -t {resources.threads} -ax sr \
            -R '@RG\\tID:{params.sname}\\tSM:{params.sname}' \
            {input.ref} \
            {input.fq1} \
            {input.fq2} \
            | samtools sort -T {params.sname}.temp -o {output.bam} - 2> {log}
        samtools index {output.bam}
        """

rule extract_reads:
    input:
        "mapped/{sample}.vectormap.bam"
    output:
        mUnmap1 = "rawreads/{sample}/{sample}_mateUnmapped_R1.fq",
        mUnmap2 = "rawreads/{sample}/{sample}_mateUnmapped_R2.fq",
        mMap1 = "rawreads/{sample}/{sample}_R1_mateMapped.fq",
        mMap2 = "rawreads/{sample}/{sample}_R2_mateMapped.fq",
        links = "rawreads/{sample}/{sample}_links.sam"
    log: config['logdir'] + "/{sample}/extract.log"
    resources:
        mem_mb=5000,
        runtime="1d",
        threads=1,
        outstr=lambda wildcards: f'logs/extract_reads/{wildcards.sample}'
    shell:
        """
        samtools fastq -f 12 {input} -1 {output.mUnmap1} -2 {output.mUnmap2}
        samtools fastq -f 68 -F 8 {input} > {output.mMap1}
        samtools fastq -f 132 -F 8 {input} > {output.mMap2}
        samtools view -f 8 -F 4 {input} > {output.links}
        """

rule cat_unmap:
    input:
        mUnmap1 = "rawreads/{sample}/{sample}_R1_mateMapped.fq",
        mUnmap2 = "rawreads/{sample}/{sample}_R2_mateMapped.fq"
    output:
        catunmap = "filtered/{sample}/{sample}.cat.unmapped.fq"
    resources:
        mem_mb = 1000,
        runtime = "1h",
        threads = 1,
        outstr=lambda wildcards: f'logs/cat/{wildcards.sample}'
    shell:
        """
        cat {input.mUnmap1} {input.mUnmap2} > {output.catunmap}
        """

rule remap_unmapped:
    input:
        ref = config['reference'],
        mUnmap1 = "rawreads/{sample}/{sample}_R1_mateMapped.fq",
        mUnmap2 = "rawreads/{sample}/{sample}_R2_mateMapped.fq",
        catunmap = "filtered/{sample}/{sample}.cat.unmapped.fq"
    log: config['logdir'] + "/{sample}/remap_unmap.log"
    params: samp = "{sample}"
    output:
        readalign = "filtered/{sample}/{sample}.readcontig.bam",
        unmaplinks = "linkage/{sample}/{sample}.readlinks.bed"
    resources:
        mem_mb=25000,
        runtime="1d",
        threads=10,
        outstr=lambda wildcards: f'logs/remap/{wildcards.sample}'
    shell:
        """
        minimap2 -t {resources.threads} -ax sr \
            -R '@RG\\tID:{params.samp}\\tSM:{params.samp}' \
            {input.ref} \
            {input.catunmap} \
            | samtools sort -T {params.samp}.utemp -o {output.readalign} - 2> {log}
        echo "Done with alignment" > {log}
        bedtools bamtobed -i {output.readalign} > {output.unmaplinks} 2> {log}
        """


# TODO: Refactor this rule to consolidate read and contig link files per sample to count actual pairs that map to the reads
# OUTPUT: breakpoint assignments and read evidence for each
rule match_mates:
    input:
        ref = config['reference'],
        links = "rawreads/{sample}/{sample}_links.sam",
        unmaplinks = "linkage/{sample}/{sample}.readlinks.bed"
    log: config['logdir'] + "/{sample}/mate_match.log"
    params:
        samp = "{sample}",
        edge = 1000,
        script = workflow.basedir + "/scripts/tabulateMates.py"
    output:
        clusters = "linkage/{sample}/{sample}.clusters.tab"
    resources:
        mem_mb=10000,
        runtime="1d",
        threads=1,
        outstr=lambda wildcards: f'logs/match_mates/{wildcards.sample}'
    shell:
        """
        python {params.script} {input.ref} {input.links} {input.unmaplinks} {output.clusters}
        """

rule create_calibrator_depth:
    input:
        ref = config['reference'],
        fq1 = lambda wildcards: fq_R1_names[wildcards.sample],
        fq2 = lambda wildcards: fq_R2_names[wildcards.sample]
    log: config['logdir'] + "/{sample}/calibrator_depth.log"
    params:
        samp = "{sample}",
        script = workflow.basedir + "/scripts/depth_estimate.py",
        calibrator = config['calibrator_region']
    output:
        bam = temp("mapped/{sample}.depthmap.bam"), 
        bai = temp("mapped/{sample}.depthmap.bam.bai"),
        depth = "mapped/{sample}.depth"
    resources:
        mem_mb=25000,
        runtime="1d",
        threads=10,
        outstr=lambda wildcards: f'logs/calibrator_depth/{wildcards.sample}'
    shell:
        """
        minimap2 -t {resources.threads} -ax sr \
            -R '@RG\\tID:{params.sname}\\tSM:{params.sname}' \
            {input.ref} \
            {input.fq1} \
            {input.fq2} \
            | samtools sort -T {params.sname}.temp -o {output.bam} - 2> {log}
        samtools index {output.bam}

        python {params.script} {output.bam} {params.calibrator} {output.depth}
        """

# TODO: Create a rule that merges alignment coordinates from paired groupings into breakpoints
# TODO: Create a routine that screens against the vector sequence to find evidence of non-construct DNA in the sample

rule mash_screen:
    input:
        library = config['mash_db'],
        fq1 = lambda wildcards: fq_R1_names[wildcards.sample],
        fq2 = lambda wildcards: fq_R2_names[wildcards.sample]
    log: config['logdir'] + "/{sample}/mash_screen.log"
    params:
        samp = "{sample}",
        script = workflow.basedir + "/scripts/depth_estimate.py",
        plasmid_names = config['contaminant_file']
    output:
        distances = "contaminant/{sample}/mash_screen.tab",
        status = "contaminant/{sample}/plasmids.tab"
    resources:
        mem_mb=25000,
        runtime="1d",
        threads=10,
        outstr=lambda wildcards: f'logs/calibrator_depth/{wildcards.sample}'
    shell:
        """

        """
# TODO: Create a rule that checks for alignment outside of the main construct sequence as a measure of contamination
# TODO: Generate an HTML report per sample with graphics to show linkage information and sample feasibility
