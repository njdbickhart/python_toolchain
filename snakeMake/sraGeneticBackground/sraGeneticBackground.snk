import os
import subprocess as sp

shell.executable("/usr/bin/bash")

configfile : "default.json"

os.makedirs("fastas", exist_ok=True)
os.makedirs("logs", exist_ok=True)

os.makedirs("final", exist_ok=True)

def getAssemblyName(v):
    return os.path.basename(v).replace('.fa', '')

SAMPLES = set([v[1] for v in config["samples"].values()])
SRAFILES = [v[0] for v in config["samples"].values()]


wildcard_constraints:
    srafiles = "|".join(SRAFILES)

onerror:
    print("Error! Mailing log...")
    shell("tail -n 100 {log} | mail -s 'sraGeneticBackgroundError' derek.bickhart@hendrix-genetics.com")
    print("Done")

rule all:
    input:
        "calls/freebayes/merged_freebayes.vcf",
        #"calls/strelka/variants.vcf.gz",
        "calls/gatk/merged_vcf.gz"

rule download_srafiles:
    #input:
    #    lambda wildcards: config["samples"][wildcards.srafiles][0]
    output:
        temp("fastas/{srafiles}_1.fastq"),
        temp("fastas/{srafiles}_2.fastq")
    params:
        download_folder = "fastas",
        mem="4000"
    threads: 3
    conda:
        "envs/base.yaml"
    log:
        "logs/{srafiles}.download.log"
    conda:
        "envs/sra.yaml"
    shell:
        "fasterq-dump {wildcards.srafiles} --split-files -O {params.download_folder} --threads {threads} 2> {log}"

rule bwa_index:
    input:
        config["assembly"]
    output:
        temp(touch("Indexed"))
    log:
        "logs/assembly_indexing.log"
    conda:
        "envs/base.yaml"
    params:
        mem = "8000"
    threads: 1
    shell:
        """
        bwa index {input} 2> {log}
        samtools faidx {input} 2> {log}
        """

rule finished_download:
    input:
        fai = "Indexed",
        fqs = expand("fastas/{srafiles}_{ext}.fastq", srafiles=SRAFILES, ext=[1,2])
    output:
        temp(touch('FinishedDownload'))

# Trick rule to create empty files for snakemake organization
rule temp_aggregate:
    input:
        finished = 'FinishedDownload'
    output:
        expand("mapped/{samples}", samples=SAMPLES)
    params:
        samples = SAMPLES
    run:
        os.makedirs("mapped", exist_ok=True)
        for i in params["samples"]:
            cmd = ['touch', 'mapped/' + i]
            print(cmd)
            sp.call(cmd)

rule aggregate_reads:
    input:
        sample = "mapped/{samples}",
        reference = config["assembly"]
    output:
        temp("mapped/{samples}.merged.bam"),
        temp("mapped/{samples}.merged.bam.bai")
    log:
        "logs/{samples}_aggregate.log"
    threads: 8
    conda:
        "envs/base.yaml"
    params:
        mem = "9000",
        config = "default.json",
        fastdir = "fastas"
    shell:
        """
        python3 {workflow.basedir}/scripts/aggregateSampleBams.py {params.config} {input.sample} {params.fastdir} {input.reference} {log}
        """

rule strelka:
    input:
        bams = expand("mapped/{samples}.merged.bam", samples=SAMPLES),
        reference = config["assembly"]
    output:
        "calls/strelka/variants.vcf.gz"
    log:
        "logs/strelka.log"
    threads: 20
    conda:
        "envs/strelka.yaml"
    params:
        mem= "50000",
        concatfiles = lambda wildcards, input: " ".join([f'--bam {x}' for x in input.bams]),
        outputfolder = "calls/strelka",
    shell:
        """
        configureStrelkaGermlineWorkflow.py {params.concatfiles} --referenceFasta {input.reference} --runDir {params.outputfolder}

        {params.outputfolder}/runWorkflow.py -m local -j 20
        """

rule freebayes:
    input:
        ref= config["assembly"],
        samples=expand("mapped/{samples}.merged.bam", samples=SAMPLES)
    output:
        "calls/freebayes/merged_freebayes.vcf"
    log:
        "logs/freebayes.log"
    conda:
        "envs/freebayes.yaml"
    params:
        extra="-g 1000 --min-repeat-entropy 1 --no-partial-observations",
        chunksize=1000000
    threads: 10
    script:
        "scripts/freebayes_lift.py"

rule haplotype_caller:
    input:
        # single or list of bam files
        bam="mapped/{samples}.merged.bam",
        ref=config["assembly"]
    output:
        temp(vcf="calls/gatk/{sample}.vcf")
    log:
        "logs/gatk/{sample}.log",
    params:
        extra="",  # optional
        java_opts="",  # optional
        mem=10000
    threads: 10
    resources:
        mem_mb=2048
    wrapper:
        "v1.18.3/bio/gatk/haplotypecaller"

rule haplotype_merger:
    input:
        vcfs = expand("calls/{sample}.vcf", sample=SAMPLES)
    output:
        "calls/gatk/merged_vcf.gz"
    log:
        "logs/gatk_merged.log"
    threads: 10
    params:
        mem=5000,
    shell:
        """
        bcftools merge --threads {threads} -O {output} -o z {input.vcfs} 2>> {log}
        """
